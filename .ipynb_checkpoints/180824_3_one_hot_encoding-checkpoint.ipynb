{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 범주형 데이터 다루기 - 원핫인코딩\n",
    "(One Hot Encoding)\n",
    "\n",
    "데이터에는 수치형 데이터와 텍스트 데이터나 범주형 데이터가 있다. 머신러닝이나 딥러닝 알고리즘은 수치로 된 데이터만 이해할 수 있다.\n",
    "그래서 기계가 이해할 수 있는 형태로 데이터를 변환해 주어야 하는데 범주형 데이터는 원핫인코딩 형태로 변환해 준다.\n",
    "원핫인코딩이란 해당되는 하나의 데이터만 1로 변경해 주고 나머지는 0으로 채워주는 것을 뜻한다.\n",
    "\n",
    "예를 들어 과일이라는 컬럼에 사과, 배, 감이 들어있다고 하자, 이 때 각각의 과일인 사과, 배, 감으로 컬럼을 만들어 주고 해당 되는 과일에만 1로 표기를 해주고 나머지 과일은 0으로 표기해 주는 것이다.\n",
    "\n",
    "#### 원핫인코딩 전\n",
    "\n",
    "|과일|\n",
    "|:---|\n",
    "|사과|\n",
    "|배|\n",
    "|감|\n",
    "|사과|\n",
    "\n",
    "#### 원핫인코딩 후\n",
    "\n",
    "|과일|과일_사과|과일_배|과일_감|\n",
    "|:---|:---:|---:|:---|\n",
    "|사과|\t1|\t0|\t0|\n",
    "|배|\t0|\t1|\t0|\n",
    "|감|\t0|\t0|\t1|\n",
    "|사과|\t1|\t0|\t0|\n",
    "\n",
    "원핫인코딩은 파이썬코드로 직접 구현해 줄 수도 있으며, 판다스나 사이킷런을 사용해서 변환해 줄 수도 있다.\n",
    "\n",
    "여기에서는 캐글의 타이타닉 데이터를 사용해서 원핫인코딩을 설명한다.\n",
    "\n",
    "데이터 다운로드 : https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(pd.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판다스를 통해 데이터를 로드해 온다.\n",
    "# 여기에서는 캐글의 타이타닉 데이터를 사용한다. \n",
    "# 데이터 다운로드 : https://www.kaggle.com/c/titanic/data \n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 데이터에 대한 정보를 보여준다.\n",
    "# 데이터의 수량과 최대값, 최소값, 평균값, 중간값 등을 확인할 수 있다.\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오브젝트 타입의 데이터만 따로 추출해 본다.\n",
    "# 이 데이터 중 카테고리 형태의 데이터가 무엇인지 보고 인코딩 해준다.\n",
    "# 원핫인코딩 뿐만 아니라 자연어처리(NLP)에서 배웠던 TF, TF-IDF의 인코딩도 해줄 수 있으며 \n",
    "# 어떤 인코딩이 적합할지 생각해 본다.\n",
    "obj_df = train.select_dtypes(include=['object']).copy()\n",
    "obj_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어느 데이터든 누락 된 데이터가 있으면 출력하도록 했다.\n",
    "# Cabin이 누락 된 데이터가 가장 많다.\n",
    "# 결측치 다루는 법은 따로 다룰 것이다.\n",
    "obj_df[obj_df.isnull().any(axis=1)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카테고리 데이터로 적합한지 확인\n",
    "obj_df[\"Cabin\"].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처리 전과 비교해 보기 위해 데이터를 복사\n",
    "train_c_df = train.copy()\n",
    "test_c_df = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "train.loc[train[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "test.loc[test[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "test.loc[test[\"Sex\"] == \"female\", \"Sex\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['Sex'] = train['Sex'].apply(lambda s: 1 if s == 'female' else 0)\n",
    "# test['Sex'] = test['Sex'].apply(lambda s: 1 if s == 'female' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이킷런의 LabelEncoder로 원핫인코딩해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카테고리 데이터를 인코딩 해준다.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 성별을 0과 1로 인코딩\n",
    "def gender_to_int(data):\n",
    "    le = LabelEncoder()\n",
    "    le.fit([\"male\",\"female\"])\n",
    "    data[\"Gender\"] = le.transform(data[\"Sex\"]) \n",
    "    return data\n",
    "\n",
    "train_c_df = gender_to_int(train_c_df)\n",
    "test_c_df = gender_to_int(test_c_df)\n",
    "train_c_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 승선위치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_c_df[\"Embarked_C\"] = train_c_df[\"Embarked\"] == \"C\"\n",
    "train_c_df[\"Embarked_S\"] = train_c_df[\"Embarked\"] == \"S\"\n",
    "train_c_df[\"Embarked_Q\"] = train_c_df[\"Embarked\"] == \"Q\"\n",
    "\n",
    "print(train.shape)\n",
    "print(train_c_df.shape)\n",
    "\n",
    "train_c_df[[\"Embarked\", \"Embarked_C\", \"Embarked_S\", \"Embarked_Q\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 판다스의 get_dummies로 원핫인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기계가 데이터를 이해할 수 있도록 \n",
    "# 카테고리 데이터를 one-hot-encoding 해준다.\n",
    "def dummy_data(data, columns):\n",
    "    for column in columns:\n",
    "        data = pd.concat([data, pd.get_dummies(data[column], prefix = column)], axis=1)\n",
    "        data = data.drop(column, axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "dummy_columns = [\"Sex\", \"Pclass\", \"Embarked\"]\n",
    "train_dummy = dummy_data(train, dummy_columns)\n",
    "test_dummy = dummy_data(test, dummy_columns)\n",
    "\n",
    "print('원핫인코딩 전 shape')\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "print('get_dummies로 원핫인코딩 후 shape')\n",
    "print(train_dummy.shape)\n",
    "print(test_dummy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이렇게 인코딩 된 데이터를 그대로 사용하게 된다면 사용하지 않는 컬럼을 drop 해주는 방법으로 피처를 생성해 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용하지 않을 컬럼을 제거해 피처로 사용할 컬럼만 남겨둔다.\n",
    "def drop_not_concerned(data, columns):\n",
    "    return data.drop(columns, axis=1)\n",
    "\n",
    "not_concerned_columns = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\n",
    "X_train = drop_not_concerned(train_dummy, not_concerned_columns)\n",
    "X_train = X_train.drop('Survived', axis=1)\n",
    "X_test = drop_not_concerned(test_dummy, not_concerned_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
